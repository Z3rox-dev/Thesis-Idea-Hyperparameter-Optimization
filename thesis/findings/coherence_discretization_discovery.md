# Scoperta: Coherence e Discretizzazione del Surrogato

**Data:** 22 Gennaio 2026

## üéØ Insight Principale

> **"Non √® la funzione vera che conta, ma come la 'vediamo' attraverso il surrogato."**

La performance di Coherence NON dipende da:
- Tipo di parametri (continui vs discreti)
- Smoothness della funzione vera sottostante
- Multimodalit√† della funzione

**Dipende invece da:** come il surrogato "discretizza" il landscape in output.

---

## üìä Evidenze Sperimentali

### Benchmark 1: HPO Reali (Contraddizione Iniziale)

| Benchmark | % Params Continui | Coherence Winrate |
|-----------|-------------------|-------------------|
| ParamNet | 87.5% | 23.3% ‚ùå |
| XGBoost Tabular | ~50% | 29.0% |
| JAHS-Bench-201 | ~60% | 46.7% |
| NN Tabular | 0% | **74.2%** ‚úÖ |

**Paradosso:** NN Tabular (0% continui) batte ParamNet (87.5% continui)!

### Benchmark 2: Smooth vs Discretized (Stessa Funzione!)

**SPHERE (dim=10, budget=200, 50 seeds):**

| Discretizzazione | COH Winrate | Delta vs Smooth |
|------------------|-------------|-----------------|
| SMOOTH | **56.0%** | - |
| BINS_10 | 0% | -56% |
| BINS_25 | 0% | -56% |
| BINS_50 | 10% | -46% |
| BINS_100 | 10% | -46% |
| BINS_200 | 40% | -16% |
| BINS_500 | 40% | -16% |
| BINS_1000 | 50% | -6% |
| BINS_2000 | **58.0%** | ‚âà0% (convergenza!) |

**ROSENBROCK (dim=10, budget=200, 50 seeds):**

| Discretizzazione | COH Winrate | Delta vs Smooth |
|------------------|-------------|-----------------|
| SMOOTH | **52.0%** | - |
| BINS_10 | 10% | -42% |
| BINS_25 | 10% | -42% |
| BINS_50 | 10% | -42% |
| BINS_100 | 10% | -42% |
| BINS_2000 | **4.0%** | -48% (NON converge!) |

---

## üî¨ Spiegazione Meccanicistica

### Perch√© Coherence fallisce su landscape discretizzati:

```
SMOOTH:                    DISCRETIZED (pochi bins):
                          
    \                          ____
     \                        |    |
      \                       |    |____
       \    ‚Üê gradiente       |         |____
        \     continuo        |              |
         \                    ‚Üê plateau + cliff
          \.                    (no gradiente locale!)
```

1. **Coherence usa i gradienti locali** per capire la "direzione giusta"
2. Su un plateau, **tutti i punti hanno lo stesso valore** ‚Üí gradiente = 0
3. Sui cliff (bordi dei gradini), il gradiente √® **infinito ma non informativo**
4. Il k-NN graph costruito su plateau ha **similarit√† coseno undefined/random**

### Soglia di Convergenza

- **SPHERE:** ~200-500 bins per convergere a smooth
- **ROSENBROCK:** >2000 bins non bastano (valle stretta richiede risoluzione enorme)

---

## üí° Implicazioni Pratiche

### Per JAHS-Bench-201:
- Usa XGBoost con 500 trees come surrogato
- Questo crea un landscape a ~500 "gradini" effettivi
- Spiega il winrate mediocre (46.7%) nonostante parametri continui

### Per HPOBench NN Tabular:
- Potrebbe usare valutazioni dirette o surrogato pi√π smooth
- Spiega l'eccellente winrate (74.2%)

### Raccomandazioni:
1. **Coherence funziona meglio** con surrogati GP o valutazioni dirette
2. **Coherence soffre** con surrogati tree-based (RF, XGBoost, LightGBM)
3. Per benchmark con surrogati tree-based, considerare:
   - Aumentare esplorazione
   - Usare smoothing del surrogato
   - Disabilitare gating su plateau

---

## üîÆ Direzioni Future

1. **GP Wrapper:** Avvolgere surrogato XGBoost con GP per smoothing
2. **Plateau Detection:** Rilevare quando siamo su un plateau e switchare strategia
3. **Local Perturbation:** Aggiungere rumore controllato per "rompere" i plateau

---

---

## üî¨ Verifica Empirica su JAHS (22 Gen 2026)

### Test: Perturbazioni Minime su Parametri Continui

**LearningRate:**
```
LR=0.100000 -> valid-acc=86.1691360474
LR=0.100010 -> valid-acc=86.1691360474  ‚Üê IDENTICO (plateau)
LR=0.100100 -> valid-acc=86.1691360474  ‚Üê IDENTICO (plateau)
LR=0.101000 -> valid-acc=86.1911010742  ‚Üê Finalmente cambia
```

**Resolution (caso estremo):**
```
Res=1.000 -> valid-acc=86.1691360474
Res=0.999 -> valid-acc=77.5862426758  ‚Üê CLIFF! (-8.5 punti!)
Res=0.990 -> valid-acc=77.5862426758  ‚Üê PLATEAU
Res=0.950 -> valid-acc=77.5862426758  ‚Üê PLATEAU
Res=0.900 -> valid-acc=77.5862426758  ‚Üê PLATEAU
```

### Conclusione Empirica

L'output XGBoost **NON √® smooth**, anche se restituisce float:
- **Plateau ampi** dove Œ¥x piccoli ‚Üí Œ¥y = 0
- **Cliff improvvisi** dove Œ¥x minimo ‚Üí Œ¥y enorme

---

## üéØ Training Reale vs Surrogato: Perch√© Coherence Dovrebbe Eccellere

### Il Training Reale √® SMOOTH per Natura

Quando fai training reale di una NN:

```python
# Cambio LR da 0.1 a 0.1001
config1 = {'lr': 0.100}  ‚Üí train() ‚Üí val_loss = 0.4523
config2 = {'lr': 0.1001} ‚Üí train() ‚Üí val_loss = 0.4521  # Leggermente diverso!
```

La loss function √® **continua e differenziabile** rispetto agli iperparametri perch√©:

1. **Il processo di training** converge a pesi leggermente diversi
2. **La validation loss** riflette queste differenze continue
3. **Non c'√® discretizzazione** artificiale

### Visualizzazione

```
SURROGATO (XGBoost):              TRAINING REALE:
                                  
     ____                              \
    |    |____                          \
    |         |____                      \
    |              |                      \.
                                           
   plateau + cliff                    gradiente continuo
   (gradiente = 0 o ‚àû)                (Coherence pu√≤ usarlo!)
```

### Perch√© Coherence Eccelle su Smooth

Coherence calcola la **similarit√† coseno** tra gradienti locali:

```
Su PLATEAU (surrogato):
  punto A: y=86.17, gradiente ‚âà [0, 0, 0, ...]
  punto B: y=86.17, gradiente ‚âà [0, 0, 0, ...]
  ‚Üí cos(0, 0) = undefined! Coherence non sa cosa fare
  
Su SMOOTH (training reale):
  punto A: y=0.4523, gradiente ‚âà [-0.02, 0.01, -0.03, ...]
  punto B: y=0.4521, gradiente ‚âà [-0.02, 0.01, -0.03, ...]
  ‚Üí cos(g_A, g_B) ‚âà 0.99 ‚Üí Alta coerenza! ‚Üí Exploita la direzione
```

### Previsione

| Scenario | Coherence Winrate Atteso |
|----------|--------------------------|
| Surrogato XGBoost (JAHS) | ~45-50% (misurato: 46.7%) |
| Surrogato GP (smooth) | ~60-70% |
| **Training Reale** | **70-80%+** |

---

## File Correlati

- Benchmark script: `thesis/benchmark_coherence_smooth_vs_discretized.py`
- Smoothing strategies: `thesis/benchmark_smoothing_strategies.py`
- Risultati JSON: `thesis/benchmark_results/coherence_smooth_vs_discretized_*.json`
- JAHS surrogato: `jahs_bench/surrogate/model.py` (usa XGBRegressor con n_estimators=500)
